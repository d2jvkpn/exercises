### Title
---

#### Chapter 2
1. Cooperative: These are tasks that yield voluntarily either by explicitly yielding or by calling
a function that suspends the task when it can’t progress further before another operation has
finished (such as making a network call). Most often, these tasks yield to a scheduler of some sort.
 Examples of this are tasks generated by async/await in Rust and JavaScript.

2. Non-cooperative: Tasks that don’t necessarily yield voluntarily. In such a system, the scheduler
must be able to pre-empt a running task, meaning that the scheduler can stop the task and take 
control over the CPU even though the task would have been able to do work and progress.
Examples of this are OS threads and Goroutines (after GO version 1.14).

3. Threads provided by the operating system
- **Creating new threads takes time**
Creating a new OS thread involves some bookkeeping and initialization overhead, so while switching
between two existing threads in the same process is pretty fast, creating new ones and discarding 
ones you don’t use anymore involves work that takes time.
- **Each thread has its own stack**
We’ll cover stacks in detail later in this book, but for now, it’s enough to know that they occupy a
 fixed size of memory. Each OS thread comes with its own stack, and even though many systems allow 
this size
- **Context switching**
As you now know, threads and schedulers are tightly connected. Context switching happens when the
CPU stops executing one thread and proceeds with another one. Even though this process is highly
optimized, it still involves storing and restoring the register state, which takes time.
- **Scheduling**
The OS can schedule tasks differently than you might expect, and every time you yield to the OS, 
you’re put in the same queue as all other threads and processes on the system.
Moreover, since there is no guarantee that the thread will resume execution on the same CPU core as 
it left off or that two tasks won’t run in parallel and try to access the same data, you need to 
synchronize data access to prevent data races and other pitfalls associated with multicore 
programming.

4. Having a separate layer of abstraction to represent concurrent tasks gives us the freedom to 
choose how we want to handle concurrent operations. If we create an abstraction over concurrent 
operations such as a future in Rust, a promise in JavaScript, or a goroutine in GO, it is up to the 
runtime implementor to decide how these concurrent tasks are handled.

5. The implementation of fibers and green threads implies that there is a runtime with a scheduler 
that’s responsible for scheduling what task (M) gets time to run on the OS thread (N). There are 
many more tasks than there are OS threads, and such a system can run perfectly fine using only one 
OS thread.
The latter case is often referred to as M:1 threading.
Goroutines is an example of a specific implementation of stackfull coroutines, but it comes with 
slight nuances. The term “coroutine” usually implies that they’re cooperative in nature, but 
Goroutines can be pre-empted by the scheduler (at least since version 1.14), thereby landing them 
in somewhat of a grey area using the categories we present here.
